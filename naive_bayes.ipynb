{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 203,
   "id": "0602aad8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop the continous valued col. \n",
    "# (capital.gain, capital.loss, hours.per.week, education.num,fnlwgt)\n",
    "# don't drop missing rows --> treat them as seperate category\n",
    "# use one hot encoding for features with categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "id": "5a00700c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "id": "dd6098c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[9, 16, 7, 15, 6, 2, 5, 42]"
      ]
     },
     "execution_count": 205,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('adult.csv')\n",
    "\n",
    "# getting the no. of unique categoriesfor each feature for the smoothing\n",
    "no_of_categories = []\n",
    "no_of_categories.append(data['workclass'].nunique())\n",
    "no_of_categories.append(data['education'].nunique())\n",
    "no_of_categories.append(data['marital.status'].nunique())\n",
    "no_of_categories.append(data['occupation'].nunique())\n",
    "no_of_categories.append(data['relationship'].nunique())\n",
    "no_of_categories.append(data['sex'].nunique())\n",
    "no_of_categories.append(data['race'].nunique())\n",
    "no_of_categories.append(data['native.country'].nunique())\n",
    "no_of_categories\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "id": "b32f00c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dropping continous valued featuers and one hot encoding our categorical featuers\n",
    "data.drop(columns=['age','capital.gain', 'capital.loss', 'hours.per.week', 'education.num','fnlwgt'],inplace=True)\n",
    "data_encoded = pd.get_dummies(data, columns=['workclass', 'education', 'marital.status','occupation','relationship','sex','race','native.country','income'], drop_first=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "id": "7a7cf295",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>workclass_?</th>\n",
       "      <th>workclass_Federal-gov</th>\n",
       "      <th>workclass_Local-gov</th>\n",
       "      <th>workclass_Never-worked</th>\n",
       "      <th>workclass_Private</th>\n",
       "      <th>workclass_Self-emp-inc</th>\n",
       "      <th>workclass_Self-emp-not-inc</th>\n",
       "      <th>workclass_State-gov</th>\n",
       "      <th>workclass_Without-pay</th>\n",
       "      <th>education_10th</th>\n",
       "      <th>...</th>\n",
       "      <th>native.country_Scotland</th>\n",
       "      <th>native.country_South</th>\n",
       "      <th>native.country_Taiwan</th>\n",
       "      <th>native.country_Thailand</th>\n",
       "      <th>native.country_Trinadad&amp;Tobago</th>\n",
       "      <th>native.country_United-States</th>\n",
       "      <th>native.country_Vietnam</th>\n",
       "      <th>native.country_Yugoslavia</th>\n",
       "      <th>income_&lt;=50K</th>\n",
       "      <th>income_&gt;50K</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 104 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   workclass_?  workclass_Federal-gov  workclass_Local-gov  \\\n",
       "0         True                  False                False   \n",
       "1        False                  False                False   \n",
       "2         True                  False                False   \n",
       "3        False                  False                False   \n",
       "4        False                  False                False   \n",
       "\n",
       "   workclass_Never-worked  workclass_Private  workclass_Self-emp-inc  \\\n",
       "0                   False              False                   False   \n",
       "1                   False               True                   False   \n",
       "2                   False              False                   False   \n",
       "3                   False               True                   False   \n",
       "4                   False               True                   False   \n",
       "\n",
       "   workclass_Self-emp-not-inc  workclass_State-gov  workclass_Without-pay  \\\n",
       "0                       False                False                  False   \n",
       "1                       False                False                  False   \n",
       "2                       False                False                  False   \n",
       "3                       False                False                  False   \n",
       "4                       False                False                  False   \n",
       "\n",
       "   education_10th  ...  native.country_Scotland  native.country_South  \\\n",
       "0           False  ...                    False                 False   \n",
       "1           False  ...                    False                 False   \n",
       "2           False  ...                    False                 False   \n",
       "3           False  ...                    False                 False   \n",
       "4           False  ...                    False                 False   \n",
       "\n",
       "   native.country_Taiwan  native.country_Thailand  \\\n",
       "0                  False                    False   \n",
       "1                  False                    False   \n",
       "2                  False                    False   \n",
       "3                  False                    False   \n",
       "4                  False                    False   \n",
       "\n",
       "   native.country_Trinadad&Tobago  native.country_United-States  \\\n",
       "0                           False                          True   \n",
       "1                           False                          True   \n",
       "2                           False                          True   \n",
       "3                           False                          True   \n",
       "4                           False                          True   \n",
       "\n",
       "   native.country_Vietnam  native.country_Yugoslavia  income_<=50K  \\\n",
       "0                   False                      False          True   \n",
       "1                   False                      False          True   \n",
       "2                   False                      False          True   \n",
       "3                   False                      False          True   \n",
       "4                   False                      False          True   \n",
       "\n",
       "   income_>50K  \n",
       "0        False  \n",
       "1        False  \n",
       "2        False  \n",
       "3        False  \n",
       "4        False  \n",
       "\n",
       "[5 rows x 104 columns]"
      ]
     },
     "execution_count": 207,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_encoded.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "id": "c62886a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data, tmp_data = train_test_split(data_encoded, test_size=0.3, random_state=42)\n",
    "val_data, test_data = train_test_split(tmp_data, test_size=0.5, random_state=42)\n",
    "# train_data          #22792 rows\n",
    "# val_data            #4884 rows\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "id": "4a7db731",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we will assume income_<=50K --> yes , income_>50K --> no       \n",
    "train_data_yes = train_data[train_data['income_<=50K'] == True] # 17291 rows \n",
    "train_data_no = train_data[train_data['income_>50K'] == True]   # 5501 rows "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "id": "f6aa00c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculating the prior probabilities of each class\n",
    "alpha = 1\n",
    "yes_samples = 17291\n",
    "no_samples = 5501\n",
    "total_samples = 22792\n",
    "prob_yes = (yes_samples*alpha) / (total_samples+(alpha*2))        # 2 for number of classes\n",
    "prob_no = (no_samples*alpha) / (total_samples+(alpha*2))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "id": "cea9b0fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "train_data_yes = train_data_yes.copy()\n",
    "train_data_no = train_data_no.copy()\n",
    "val_data = val_data.copy()\n",
    "test_data = test_data.copy()\n",
    "\n",
    "# getting label col. for validation and testing data\n",
    "val_data_labels = val_data['income_<=50K'].values\n",
    "test_data_labels = test_data['income_<=50K'].values\n",
    "\n",
    "# dropping target col.\n",
    "train_data_yes.drop(columns=['income_<=50K','income_>50K'], inplace=True)\n",
    "train_data_no.drop(columns=['income_<=50K','income_>50K'], inplace=True)\n",
    "val_data.drop(columns=['income_<=50K','income_>50K'], inplace=True)\n",
    "test_data.drop(columns=['income_<=50K','income_>50K'], inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "id": "15482e88",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculating the likelihood\n",
    "\n",
    "col_names = train_data_yes.columns.to_numpy()\n",
    "prob_given_yes = []\n",
    "prob_given_no = []\n",
    "values_yes = train_data_yes.to_numpy()\n",
    "values_no = train_data_no.to_numpy()\n",
    "\n",
    "# calculating prob(features/yes)\n",
    "category_index = 0\n",
    "category_counter = no_of_categories[category_index] - 1\n",
    "for col_idx, col in enumerate(values_yes.T):\n",
    "    count = col.sum()\n",
    "    prob_given_yes.append((count+alpha)/(yes_samples+(alpha*no_of_categories[category_index])))\n",
    "    if col_idx ==  category_counter:\n",
    "        category_index+=1\n",
    "        if category_index < len(no_of_categories) - 1:\n",
    "            category_counter += no_of_categories[category_index] - 1\n",
    "\n",
    "\n",
    "\n",
    "# calculating prob(features/no)\n",
    "category_index = 0\n",
    "category_counter = no_of_categories[category_index] - 1\n",
    "for col_idx, col in enumerate(values_no.T):\n",
    "    count = col.sum()\n",
    "    prob_given_no.append((count+alpha)/(no_samples+(alpha*no_of_categories[category_index])))\n",
    "    if col_idx == category_counter:\n",
    "        category_index+=1\n",
    "        if category_index < len(no_of_categories) - 1:\n",
    "            category_counter += no_of_categories[category_index] - 1 \n",
    "\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "id": "1de6e38e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of correct predictions = 3856\n",
      "miss classification rate = 0.2104832104832105\n"
     ]
    }
   ],
   "source": [
    "# calculating prediction\n",
    "# prob_yes, prob_no, prob_given_yes, prob_given_no, val_data_labels\n",
    "val_data_arr = val_data.to_numpy()  #4884 rows\n",
    "log_yes = np.log(prob_yes)\n",
    "log_no = np.log(prob_no)\n",
    "prediction_yes = []         # supposed to be 4884\n",
    "prediction_no = []\n",
    "income_low = []\t    # yes       <=50 --> if false then sample is income high\n",
    "no_of_correct_predictions = 0\n",
    "\n",
    "# calculate the prob. that its a yes class\n",
    "for i in range(0,len(val_data_arr)):\n",
    "    prob = log_yes\n",
    "    for j in range(0,len(prob_given_yes)):\n",
    "        if val_data_arr[i][j] == True:\n",
    "            prob+= np.log(prob_given_yes[j])\n",
    "    prediction_yes.append(prob)\n",
    "\n",
    "\n",
    "# calculate the prob. that its a no class\n",
    "for i in range(0,len(val_data_arr)):\n",
    "    prob = log_no\n",
    "    for j in range(0,len(prob_given_no)):\n",
    "        if val_data_arr[i][j] == True:\n",
    "            prob+= np.log(prob_given_no[j])\n",
    "    prediction_no.append(prob)\n",
    "\n",
    "# deciding which class has higher prob.\n",
    "for i in range(0,len(val_data_arr)):\n",
    "    if prediction_yes[i] > prediction_no[i]:\n",
    "        income_low.append(True)\n",
    "    else:\n",
    "        income_low.append(False)\n",
    "\n",
    "for i in range(0,len(income_low)):\n",
    "    if income_low[i] == val_data_labels[i]:\n",
    "        no_of_correct_predictions+=1\n",
    "\n",
    "\n",
    "print(f\"number of correct predictions = {no_of_correct_predictions}\")\n",
    "print(f\"miss classification rate = {1-(no_of_correct_predictions/len(val_data_labels))}\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
